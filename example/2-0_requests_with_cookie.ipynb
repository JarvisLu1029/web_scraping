{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e723eaaf",
   "metadata": {},
   "source": [
    "### Requests 夾帶 headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5058b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "# yahoo 海外股市頁面\n",
    "url = \"https://finance.yahoo.com/quote/TSLA/\"\n",
    "\n",
    "# 用 requests 的 get 方法把網頁抓下來\n",
    "res = requests.get(url) # 直接用 requests 抓會被擋下來\n",
    "soup = bs(res.text, \"lxml\")\n",
    "print(soup) # <html><body><p>Edge: Too Many Requests</p></body></html>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cd710a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "url = \"https://finance.yahoo.com/quote/TSLA/\"\n",
    "\n",
    "# 加上 headers 模擬瀏覽器行為\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/\"\n",
    "}\n",
    "\n",
    "res = requests.get(url, headers=headers)\n",
    "soup = bs(res.text, \"lxml\")\n",
    "\n",
    "price = soup.select_one(\".container.yf-16vvaki .yf-ipw1h0.base\").text\n",
    "print(\"股價:\", price)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f975341",
   "metadata": {},
   "source": [
    "### Requests 夾帶 headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aae9d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    " # PTT Gossiiping (八卦版) \n",
    "url = \"https://www.ptt.cc/bbs/Gossiping/index.html\"\n",
    "\n",
    "# 首頁網址\n",
    "prefix = 'https://www.ptt.cc'\n",
    "\n",
    "# 設定 cookie\n",
    "my_cookies = {\n",
    "    \"over18\": \"1\"\n",
    "}\n",
    "\n",
    "# 用 requests 的 get 方法把網頁抓下來\n",
    "res = requests.get(url, cookies = my_cookies) \n",
    "\n",
    "# 指定 lxml 作為解析器\n",
    "soup = bs(res.text, \"lxml\")\n",
    "\n",
    "# 顯示連結列表\n",
    "for a in soup.select('div.r-ent > div.title > a'):\n",
    "    print(a.get_text())\n",
    "    print(prefix + a['href'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ispan_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
